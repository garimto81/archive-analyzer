"""NAS Auto Sync Web Monitoring Application

Issue #43: Docker ì„œë²„ ë°°í¬ + GUI ëª¨ë‹ˆí„°ë§

FastAPI ê¸°ë°˜ ì›¹ ëŒ€ì‹œë³´ë“œ:
- ì‹¤ì‹œê°„ ë™ê¸°í™” ìƒíƒœ
- íŒŒì¼ ë³€ê²½ ì´ë ¥ ì¡°íšŒ
- ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° (WebSocket)
- ìˆ˜ë™ ë™ê¸°í™”/ì •í•©ì„± ê²€ì¦ íŠ¸ë¦¬ê±°

Usage:
    uvicorn archive_analyzer.web.app:app --host 0.0.0.0 --port 8080
"""

import asyncio
import logging
import os
import sqlite3
from collections import deque
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Deque, Dict, List, Optional

from fastapi import BackgroundTasks, FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from starlette.requests import Request

logger = logging.getLogger(__name__)

# =============================================================================
# Configuration
# =============================================================================


@dataclass
class WebConfig:
    """Web ëª¨ë‹ˆí„°ë§ ì„¤ì •"""

    archive_db: str = "data/output/archive.db"
    pokervod_db: str = "D:/AI/claude01/shared-data/pokervod.db"
    nas_mount_path: str = "Z:/GGPNAs/ARCHIVE"
    sync_interval: int = 1800
    log_buffer_size: int = 1000
    host: str = "0.0.0.0"
    port: int = 8080

    def __post_init__(self):
        self.archive_db = os.environ.get("ARCHIVE_DB", self.archive_db)
        self.pokervod_db = os.environ.get("POKERVOD_DB", self.pokervod_db)
        self.nas_mount_path = os.environ.get("NAS_MOUNT_PATH", self.nas_mount_path)
        if interval := os.environ.get("SYNC_INTERVAL"):
            self.sync_interval = int(interval)
        if port := os.environ.get("WEB_PORT"):
            self.port = int(port)


# =============================================================================
# Service State
# =============================================================================


@dataclass
class ServiceState:
    """ì„œë¹„ìŠ¤ ìƒíƒœ ê´€ë¦¬"""

    is_running: bool = False
    last_sync_time: Optional[datetime] = None
    last_sync_result: Optional[Dict[str, Any]] = None
    sync_in_progress: bool = False
    error_message: Optional[str] = None
    log_buffer: Deque[str] = field(default_factory=lambda: deque(maxlen=1000))
    connected_clients: List[WebSocket] = field(default_factory=list)
    config: WebConfig = field(default_factory=WebConfig)

    # Issue #49: Google Sheets ë™ê¸°í™” ì—°ë™ (Optional)
    # ISheetsSync Protocolì„ êµ¬í˜„í•˜ëŠ” ì–´ëŒ‘í„° (Noneì´ë©´ ë¹„í™œì„±í™”)
    sheets_sync: Optional[Any] = None  # Type: Optional[ISheetsSync]


state = ServiceState()


# =============================================================================
# Log Handler for WebSocket Streaming
# =============================================================================


class WebSocketLogHandler(logging.Handler):
    """WebSocketìœ¼ë¡œ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°"""

    def __init__(self, state: ServiceState):
        super().__init__()
        self.state = state
        self.setFormatter(
            logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
        )

    def emit(self, record: logging.LogRecord):
        try:
            msg = self.format(record)
            self.state.log_buffer.append(msg)
            # WebSocket í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
            asyncio.create_task(self._broadcast(msg))
        except Exception:
            pass

    async def _broadcast(self, message: str):
        disconnected = []
        for client in self.state.connected_clients:
            try:
                await client.send_text(message)
            except Exception:
                disconnected.append(client)
        for client in disconnected:
            self.state.connected_clients.remove(client)


# =============================================================================
# Database Helpers
# =============================================================================


def get_db_stats(db_path: str) -> Dict[str, Any]:
    """DB í†µê³„ ì¡°íšŒ (archive.db, pokervod.db ë‘˜ ë‹¤ ì§€ì›)"""
    if not Path(db_path).exists():
        return {"error": f"DB not found: {db_path}"}

    conn = sqlite3.connect(db_path)
    try:
        stats = {}

        # í…Œì´ë¸” ì»¬ëŸ¼ í™•ì¸
        cursor = conn.execute("PRAGMA table_info(files)")
        columns = {row[1] for row in cursor.fetchall()}

        # ì „ì²´ íŒŒì¼ ìˆ˜
        cursor = conn.execute("SELECT COUNT(*) FROM files")
        stats["total_files"] = cursor.fetchone()[0]

        # ìƒíƒœë³„ íŒŒì¼ ìˆ˜ (ìŠ¤í‚¤ë§ˆì— ë”°ë¼ ë‹¤ë¥¸ ì»¬ëŸ¼ ì‚¬ìš©)
        if "scan_status" in columns:
            # archive.db
            cursor = conn.execute(
                """SELECT COALESCE(scan_status, 'unknown'), COUNT(*)
                   FROM files GROUP BY scan_status"""
            )
            stats["by_status"] = dict(cursor.fetchall())
        elif "analysis_status" in columns:
            # pokervod.db
            cursor = conn.execute(
                """SELECT COALESCE(analysis_status, 'unknown'), COUNT(*)
                   FROM files GROUP BY analysis_status"""
            )
            stats["by_status"] = dict(cursor.fetchall())
        else:
            stats["by_status"] = {}

        # íŒŒì¼ íƒ€ì…ë³„ (archive.db only)
        if "file_type" in columns:
            cursor = conn.execute(
                """SELECT file_type, COUNT(*)
                   FROM files GROUP BY file_type
                   ORDER BY COUNT(*) DESC LIMIT 10"""
            )
            stats["by_type"] = dict(cursor.fetchall())
        elif "codec" in columns:
            # pokervod.db - codecë³„ í†µê³„
            cursor = conn.execute(
                """SELECT COALESCE(codec, 'unknown'), COUNT(*)
                   FROM files GROUP BY codec
                   ORDER BY COUNT(*) DESC LIMIT 10"""
            )
            stats["by_type"] = dict(cursor.fetchall())
        else:
            stats["by_type"] = {}

        # ìµœê·¼ íŒŒì¼ (ìŠ¤í‚¤ë§ˆì— ë”°ë¼ ë‹¤ë¥¸ ì»¬ëŸ¼)
        if "path" in columns:
            # archive.db
            time_col = "created_at" if "created_at" in columns else "modified_at"
            cursor = conn.execute(
                f"""SELECT path, filename, {time_col}
                   FROM files
                   ORDER BY {time_col} DESC LIMIT 5"""
            )
            stats["recent_files"] = [
                {"path": r[0], "filename": r[1], "updated_at": r[2]}
                for r in cursor.fetchall()
            ]
        elif "nas_path" in columns:
            # pokervod.db
            cursor = conn.execute(
                """SELECT nas_path, filename, updated_at
                   FROM files
                   ORDER BY updated_at DESC LIMIT 5"""
            )
            stats["recent_files"] = [
                {"path": r[0], "filename": r[1], "updated_at": r[2]}
                for r in cursor.fetchall()
            ]
        else:
            stats["recent_files"] = []

        # DB íŒŒì¼ í¬ê¸°
        stats["db_size_mb"] = round(Path(db_path).stat().st_size / (1024 * 1024), 2)

        return stats

    except Exception as e:
        return {"error": str(e)}
    finally:
        conn.close()


# HLS í˜¸í™˜ í™•ì¥ì (sync.pyì™€ ë™ì¼)
HLS_COMPATIBLE_EXTENSIONS = ("mp4", "mov", "ts", "m4v", "m2ts", "mts")

# Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ  ë¶„ë¥˜
NOT_SYNCED_REASONS = {
    "hls_incompatible": "HLS ë¹„í˜¸í™˜ í¬ë§·",
    "duplicate_excluded": "ì¤‘ë³µ íŒŒì¼ ì œì™¸",
    "non_video": "ë¹„ë””ì˜¤ ì•„ë‹˜",
    "pending_sync": "ë™ê¸°í™” ëŒ€ê¸°",
}

# ë¹„ë””ì˜¤ í™•ì¥ì
VIDEO_EXTENSIONS = ("mp4", "mov", "ts", "m4v", "m2ts", "mts", "mkv", "avi", "wmv", "flv", "webm", "mxf")

# HLS ë¹„í˜¸í™˜ í™•ì¥ì
NON_HLS_EXTENSIONS = ("mxf", "webm", "mkv", "avi", "wmv", "flv")


def get_matching_summary(
    archive_db: str, pokervod_db: str
) -> Dict[str, Any]:
    """ë§¤ì¹­ ìš”ì•½ í†µê³„ ê³„ì‚° (Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ ë³„ ë¶„ë¥˜)"""
    summary = {
        "synced": 0,
        "not_synced": 0,
        "duplicates": 0,
        "catalogs": [],
        # Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ ë³„ ìƒì„¸
        "not_synced_reasons": {
            "hls_incompatible": 0,
            "duplicate_excluded": 0,
            "non_video": 0,
            "pending_sync": 0,
        },
    }

    if not Path(archive_db).exists():
        return summary

    conn_archive = sqlite3.connect(archive_db)
    conn_pokervod = None
    pokervod_filenames = set()

    if Path(pokervod_db).exists():
        conn_pokervod = sqlite3.connect(pokervod_db)
        cursor = conn_pokervod.execute("SELECT filename FROM files")
        pokervod_filenames = {row[0] for row in cursor.fetchall()}

    try:
        # archive.db ì „ì²´ íŒŒì¼ ì¡°íšŒ
        cursor = conn_archive.execute("SELECT filename FROM files")
        all_files = [row[0] for row in cursor.fetchall()]

        # ì¤‘ë³µ íŒŒì¼ëª… ì°¾ê¸°
        cursor = conn_archive.execute(
            """SELECT filename FROM files
               GROUP BY filename HAVING COUNT(*) > 1"""
        )
        duplicate_filenames = {row[0] for row in cursor.fetchall()}

        # Issue #51: íŒŒì¼ë³„ ì‚¬ìœ  ë¶„ë¥˜
        synced = 0
        hls_incompatible = 0
        duplicate_excluded = 0
        non_video = 0
        pending_sync = 0

        for filename in all_files:
            ext = filename.split(".")[-1].lower() if "." in filename else ""
            is_video = ext in VIDEO_EXTENSIONS
            is_hls_compatible = ext in HLS_COMPATIBLE_EXTENSIONS
            is_synced = filename in pokervod_filenames
            is_duplicate = filename in duplicate_filenames

            if is_synced:
                synced += 1
            elif not is_video:
                non_video += 1
            elif not is_hls_compatible:
                hls_incompatible += 1
            elif is_duplicate:
                # ì¤‘ë³µ íŒŒì¼ ì¤‘ í•˜ë‚˜ë§Œ ë™ê¸°í™”ë¨ - ë‚˜ë¨¸ì§€ëŠ” ì œì™¸
                duplicate_excluded += 1
            else:
                pending_sync += 1

        # ì¹´íƒˆë¡œê·¸ë³„ í†µê³„
        cursor = conn_archive.execute(
            """SELECT
                   CASE
                       WHEN path LIKE '%/WSOP/%' OR path LIKE 'WSOP/%' THEN 'WSOP'
                       WHEN path LIKE '%/HCL/%' OR path LIKE 'HCL/%' THEN 'HCL'
                       WHEN path LIKE '%/PAD/%' OR path LIKE 'PAD/%' THEN 'PAD'
                       WHEN path LIKE '%/MPP/%' OR path LIKE 'MPP/%' THEN 'MPP'
                       WHEN path LIKE '%/GOG/%' OR path LIKE 'GOG/%' THEN 'GOG'
                       WHEN path LIKE '%/GGMillions/%' OR path LIKE 'GGMillions/%' THEN 'GGMillions'
                       ELSE 'Other'
                   END as catalog,
                   COUNT(*) as count
               FROM files
               GROUP BY catalog
               ORDER BY count DESC"""
        )
        catalogs = [{"name": row[0], "count": row[1]} for row in cursor.fetchall()]

        not_synced_total = hls_incompatible + duplicate_excluded + non_video + pending_sync

        summary = {
            "synced": synced,
            "not_synced": not_synced_total,
            "duplicates": duplicate_excluded,
            "catalogs": catalogs,
            "not_synced_reasons": {
                "hls_incompatible": hls_incompatible,
                "duplicate_excluded": duplicate_excluded,
                "non_video": non_video,
                "pending_sync": pending_sync,
            },
        }

    except Exception as e:
        logger.error(f"ë§¤ì¹­ ìš”ì•½ ê³„ì‚° ì˜¤ë¥˜: {e}")
    finally:
        conn_archive.close()
        if conn_pokervod:
            conn_pokervod.close()

    return summary


def get_matching_items(
    archive_db: str,
    pokervod_db: str,
    page: int = 1,
    per_page: int = 20,
    status_filter: Optional[str] = None,
    sort_by: str = "filename",
    sort_order: str = "asc",
) -> tuple:
    """1:1 ë§¤ì¹­ ì•„ì´í…œ ëª©ë¡ ì¡°íšŒ (Issue #51: ì •ë ¬ + ë¯¸ë“±ë¡ ì‚¬ìœ )

    Args:
        archive_db: archive.db ê²½ë¡œ
        pokervod_db: pokervod.db ê²½ë¡œ
        page: í˜ì´ì§€ ë²ˆí˜¸
        per_page: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜
        status_filter: ìƒíƒœ í•„í„° (synced, not_synced, synced_with_duplicates)
        sort_by: ì •ë ¬ ê¸°ì¤€ (filename, size, status, path, modified_at)
        sort_order: ì •ë ¬ ìˆœì„œ (asc, desc)
    """
    items = []
    total = 0
    summary = {"synced": 0, "not_synced": 0, "synced_with_duplicates": 0}

    if not Path(archive_db).exists():
        return items, total, summary

    conn_archive = sqlite3.connect(archive_db)
    conn_pokervod = None
    pokervod_files = {}

    if Path(pokervod_db).exists():
        conn_pokervod = sqlite3.connect(pokervod_db)
        # pokervod.dbì˜ íŒŒì¼ë“¤ì„ filenameìœ¼ë¡œ ì¸ë±ì‹±
        cursor = conn_pokervod.execute(
            "SELECT id, filename, nas_path, size_bytes FROM files"
        )
        for row in cursor.fetchall():
            pokervod_files[row[1]] = {
                "id": row[0],
                "filename": row[1],
                "nas_path": row[2],
                "size_bytes": row[3],
            }

    try:
        # ì¤‘ë³µ íŒŒì¼ ëª©ë¡ (ë™ì¼ filenameì´ ì—¬ëŸ¬ pathì— ì¡´ì¬)
        cursor = conn_archive.execute(
            """SELECT filename FROM files
               GROUP BY filename HAVING COUNT(*) > 1"""
        )
        duplicate_filenames = {row[0] for row in cursor.fetchall()}

        # ëª¨ë“  íŒŒì¼ ì¡°íšŒ (modified_at í¬í•¨)
        cursor = conn_archive.execute(
            """SELECT id, path, filename, file_type, size_bytes, modified_at
               FROM files
               ORDER BY id"""
        )

        all_items = []
        for row in cursor.fetchall():
            source_id, path, filename, file_type, size_bytes, modified_at = row

            # í™•ì¥ìë¡œ HLS í˜¸í™˜ ì—¬ë¶€ í™•ì¸
            ext = filename.split(".")[-1].lower() if "." in filename else ""
            is_hls_compatible = ext in HLS_COMPATIBLE_EXTENSIONS
            is_video = ext in VIDEO_EXTENSIONS

            # ë§¤ì¹­ ìƒíƒœ ê²°ì •
            target_info = pokervod_files.get(filename)
            is_duplicate = filename in duplicate_filenames

            # Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ  ë¶„ë¥˜
            not_synced_reason = None
            if target_info:
                if is_duplicate:
                    status = "synced_with_duplicates"
                    summary["synced_with_duplicates"] += 1
                else:
                    status = "synced"
                    summary["synced"] += 1
            else:
                status = "not_synced"
                summary["not_synced"] += 1
                # ë¯¸ë“±ë¡ ì‚¬ìœ  ê²°ì •
                if not is_video:
                    not_synced_reason = "non_video"
                elif not is_hls_compatible:
                    not_synced_reason = "hls_incompatible"
                elif is_duplicate:
                    not_synced_reason = "duplicate_excluded"
                else:
                    not_synced_reason = "pending_sync"

            item = {
                "status": status,
                "not_synced_reason": not_synced_reason,
                "source": {
                    "id": source_id,
                    "path": path,
                    "filename": filename,
                    "file_type": file_type,
                    "size_bytes": size_bytes,
                    "modified_at": modified_at,
                },
                "target": target_info,
                "is_hls_compatible": is_hls_compatible,
            }

            if is_duplicate:
                # ì¤‘ë³µ ê²½ë¡œ ì¡°íšŒ
                dup_cursor = conn_archive.execute(
                    "SELECT id, path FROM files WHERE filename = ? AND id != ?",
                    (filename, source_id),
                )
                item["duplicates"] = [
                    {"id": r[0], "path": r[1]} for r in dup_cursor.fetchall()
                ]
            else:
                item["duplicates"] = []

            all_items.append(item)

        # í•„í„° ì ìš© (í•„í„°ë§ í›„ total ê³„ì‚°)
        if status_filter:
            filtered_items = [item for item in all_items if item["status"] == status_filter]
        else:
            filtered_items = all_items

        # Issue #51: ì •ë ¬ ì ìš©
        sort_key_map = {
            "filename": lambda x: (x["source"]["filename"] or "").lower(),
            "size": lambda x: x["source"]["size_bytes"] or 0,
            "status": lambda x: x["status"],
            "path": lambda x: (x["source"]["path"] or "").lower(),
            "modified_at": lambda x: x["source"]["modified_at"] or "",
        }
        sort_key = sort_key_map.get(sort_by, sort_key_map["filename"])
        reverse = sort_order.lower() == "desc"
        filtered_items.sort(key=sort_key, reverse=reverse)

        # í•„í„° ì ìš© í›„ total ê³„ì‚°
        total = len(filtered_items)

        # í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
        offset = (page - 1) * per_page
        items = filtered_items[offset : offset + per_page]

    except Exception as e:
        logger.error(f"ë§¤ì¹­ ì•„ì´í…œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
    finally:
        conn_archive.close()
        if conn_pokervod:
            conn_pokervod.close()

    return items, total, summary


def get_catalog_tree(archive_db: str, pokervod_db: str) -> List[Dict[str, Any]]:
    """ì¹´íƒˆë¡œê·¸ë³„ íŠ¸ë¦¬ êµ¬ì¡° ìƒì„± (Issue #51: ì¬ê·€ì  í´ë” êµ¬ì¡°)"""
    catalogs = []

    if not Path(archive_db).exists():
        return catalogs

    conn_archive = sqlite3.connect(archive_db)
    conn_pokervod = None
    pokervod_files = set()

    if Path(pokervod_db).exists():
        conn_pokervod = sqlite3.connect(pokervod_db)
        cursor = conn_pokervod.execute("SELECT filename FROM files")
        pokervod_files = {row[0] for row in cursor.fetchall()}

    try:
        # ì¹´íƒˆë¡œê·¸ ì •ì˜
        catalog_patterns = [
            ("WSOP", "%WSOP%"),
            ("HCL", "%HCL%"),
            ("PAD", "%PAD%"),
            ("MPP", "%MPP%"),
            ("GOG", "%GOG%"),
            ("GGMillions", "%GGMillions%"),
        ]

        for catalog_name, pattern in catalog_patterns:
            cursor = conn_archive.execute(
                """SELECT id, path, filename, size_bytes, parent_folder
                   FROM files WHERE path LIKE ?
                   ORDER BY path""",
                (pattern,),
            )
            files = cursor.fetchall()

            if not files:
                continue

            synced = sum(1 for f in files if f[2] in pokervod_files)
            not_synced = len(files) - synced

            # Issue #51: ì¬ê·€ì  í´ë” íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
            folder_tree = _build_folder_tree(files, pokervod_files)

            catalog = {
                "name": catalog_name,
                "total_files": len(files),
                "synced": synced,
                "not_synced": not_synced,
                "children": folder_tree,
            }
            catalogs.append(catalog)

    except Exception as e:
        logger.error(f"ì¹´íƒˆë¡œê·¸ íŠ¸ë¦¬ ìƒì„± ì˜¤ë¥˜: {e}")
    finally:
        conn_archive.close()
        if conn_pokervod:
            conn_pokervod.close()

    return catalogs


def _build_folder_tree(
    files: List[tuple], pokervod_files: set
) -> List[Dict[str, Any]]:
    """íŒŒì¼ ëª©ë¡ì—ì„œ ê³„ì¸µì  í´ë” íŠ¸ë¦¬ ìƒì„± (Issue #51)

    Args:
        files: [(id, path, filename, size_bytes, parent_folder), ...]
        pokervod_files: pokervod.dbì— ìˆëŠ” íŒŒì¼ëª… ì§‘í•©

    Returns:
        ê³„ì¸µì  íŠ¸ë¦¬ êµ¬ì¡° (1ë‹¨-2ë‹¨-3ë‹¨-4ë‹¨...)
    """
    if not files:
        return []

    # 1. í´ë”ë³„ íŒŒì¼ ìˆ˜ì§‘
    folder_files: Dict[str, List[Dict]] = {}  # folder_path -> [file_info, ...]

    for file_id, path, filename, size_bytes, parent_folder in files:
        if not parent_folder:
            parent_folder = "/"

        if parent_folder not in folder_files:
            folder_files[parent_folder] = []

        is_synced = filename in pokervod_files
        folder_files[parent_folder].append({
            "id": file_id,
            "name": filename,
            "path": path,
            "size_bytes": size_bytes,
            "status": "synced" if is_synced else "not_synced",
        })

    # 2. ê³µí†µ prefix ì°¾ê¸° (ë£¨íŠ¸ ê²½ë¡œ)
    all_paths = list(folder_files.keys())
    if not all_paths:
        return []

    # ê°€ì¥ ì§§ì€ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³µí†µ prefix ì°¾ê¸°
    common_prefix = all_paths[0]
    for p in all_paths[1:]:
        while not p.startswith(common_prefix):
            common_prefix = "/".join(common_prefix.split("/")[:-1])
            if not common_prefix:
                break

    # 3. ê³„ì¸µì  íŠ¸ë¦¬ êµ¬ì¡° êµ¬ì¶•
    tree_dict: Dict[str, Dict] = {}  # path -> node

    for folder_path, file_list in folder_files.items():
        # ê³µí†µ prefix ì´í›„ì˜ ìƒëŒ€ ê²½ë¡œ
        if common_prefix and folder_path.startswith(common_prefix):
            rel_path = folder_path[len(common_prefix):].strip("/")
        else:
            rel_path = folder_path.split("/")[-1] if "/" in folder_path else folder_path

        # ê²½ë¡œ ë¶„í•´
        parts = rel_path.split("/") if rel_path else []

        # íŒŒì¼ í†µê³„
        synced = sum(1 for f in file_list if f["status"] == "synced")
        not_synced = len(file_list) - synced

        # í˜„ì¬ í´ë” ë…¸ë“œ ìƒì„±
        current_path = ""
        for i, part in enumerate(parts):
            parent_path = current_path
            current_path = f"{current_path}/{part}" if current_path else part

            if current_path not in tree_dict:
                tree_dict[current_path] = {
                    "type": "folder",
                    "name": part,
                    "path": folder_path if i == len(parts) - 1 else "",
                    "depth": i + 1,
                    "children": {},
                    "files": [],
                    "synced": 0,
                    "not_synced": 0,
                    "total_files": 0,
                }

            # ë§ˆì§€ë§‰ ë ˆë²¨ì´ë©´ íŒŒì¼ ì¶”ê°€
            if i == len(parts) - 1:
                tree_dict[current_path]["files"] = file_list  # ëª¨ë“  íŒŒì¼
                tree_dict[current_path]["synced"] = synced
                tree_dict[current_path]["not_synced"] = not_synced
                tree_dict[current_path]["total_files"] = len(file_list)
                tree_dict[current_path]["path"] = folder_path

            # ë¶€ëª¨-ìì‹ ê´€ê³„ ì„¤ì •
            if parent_path and parent_path in tree_dict:
                tree_dict[parent_path]["children"][current_path] = tree_dict[current_path]

    # 4. íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ë³€í™˜ (ë£¨íŠ¸ ë…¸ë“œë“¤ë§Œ ì¶”ì¶œ)
    root_nodes = []
    for path, node in tree_dict.items():
        # 1ë‹¨ê³„ í´ë”ë§Œ (ë¶€ëª¨ê°€ ì—†ëŠ” ë…¸ë“œ)
        if "/" not in path:
            root_nodes.append(_convert_tree_node(node, tree_dict))

    # í†µê³„ ì§‘ê³„ (í•˜ìœ„ í´ë” í¬í•¨)
    for node in root_nodes:
        _aggregate_stats(node)

    return sorted(root_nodes, key=lambda x: x["name"])


def _convert_tree_node(node: Dict, tree_dict: Dict) -> Dict:
    """íŠ¸ë¦¬ ë…¸ë“œë¥¼ ì¬ê·€ì ìœ¼ë¡œ ë³€í™˜"""
    children = []
    for child_path, child_node in node.get("children", {}).items():
        children.append(_convert_tree_node(child_node, tree_dict))

    return {
        "type": "folder",
        "name": node["name"],
        "path": node.get("path", ""),
        "depth": node.get("depth", 1),
        "children": sorted(children, key=lambda x: x["name"]),
        "files": node.get("files", []),
        "synced": node.get("synced", 0),
        "not_synced": node.get("not_synced", 0),
        "total_files": node.get("total_files", 0),
    }


def _aggregate_stats(node: Dict) -> tuple:
    """í•˜ìœ„ í´ë” í†µê³„ë¥¼ ìƒìœ„ë¡œ ì§‘ê³„"""
    total_files = node.get("total_files", 0)
    synced = node.get("synced", 0)
    not_synced = node.get("not_synced", 0)

    for child in node.get("children", []):
        child_total, child_synced, child_not_synced = _aggregate_stats(child)
        total_files += child_total
        synced += child_synced
        not_synced += child_not_synced

    node["total_files_recursive"] = total_files
    node["synced_recursive"] = synced
    node["not_synced_recursive"] = not_synced

    return total_files, synced, not_synced


def get_file_history(db_path: str, limit: int = 50) -> List[Dict[str, Any]]:
    """íŒŒì¼ ë³€ê²½ ì´ë ¥ ì¡°íšŒ"""
    if not Path(db_path).exists():
        return []

    conn = sqlite3.connect(db_path)
    try:
        # file_history í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        cursor = conn.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name='file_history'"
        )
        if not cursor.fetchone():
            return []

        cursor = conn.execute(
            """SELECT fh.id, fh.file_id, fh.event_type, fh.old_path, fh.new_path,
                      fh.detected_at, f.filename
               FROM file_history fh
               LEFT JOIN files f ON fh.file_id = f.id
               ORDER BY fh.detected_at DESC
               LIMIT ?""",
            (limit,),
        )

        return [
            {
                "id": r[0],
                "file_id": r[1],
                "event_type": r[2],
                "old_path": r[3],
                "new_path": r[4],
                "detected_at": r[5],
                "filename": r[6],
            }
            for r in cursor.fetchall()
        ]

    except Exception as e:
        logger.error(f"íŒŒì¼ ì´ë ¥ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return []
    finally:
        conn.close()


# =============================================================================
# Background Tasks
# =============================================================================


def run_sync_task():
    """ë™ê¸°í™” ì‘ì—… ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)"""
    from archive_analyzer.nas_auto_sync import AutoSyncConfig, NASAutoSync

    state.sync_in_progress = True
    state.error_message = None

    try:
        config = AutoSyncConfig(
            archive_db=state.config.archive_db,
            pokervod_db=state.config.pokervod_db,
            sync_interval_seconds=state.config.sync_interval,
        )
        service = NASAutoSync(config)
        result = service.run_once()

        state.last_sync_time = datetime.now()
        state.last_sync_result = result
        logger.info(f"ë™ê¸°í™” ì™„ë£Œ: {result}")

    except Exception as e:
        state.error_message = str(e)
        logger.error(f"ë™ê¸°í™” ì‹¤íŒ¨: {e}")

    finally:
        state.sync_in_progress = False


def run_reconcile_task(dry_run: bool = True):
    """ì •í•©ì„± ê²€ì¦ ì‘ì—… ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)"""
    from archive_analyzer.nas_auto_sync import AutoSyncConfig, NASAutoSync

    state.sync_in_progress = True
    state.error_message = None

    try:
        config = AutoSyncConfig(
            archive_db=state.config.archive_db,
            pokervod_db=state.config.pokervod_db,
        )
        service = NASAutoSync(config)
        result = service.run_reconcile(
            nas_mount_path=state.config.nas_mount_path,
            dry_run=dry_run,
        )

        state.last_sync_time = datetime.now()
        state.last_sync_result = {"reconcile": result}
        logger.info(f"ì •í•©ì„± ê²€ì¦ ì™„ë£Œ: {result}")

    except Exception as e:
        state.error_message = str(e)
        logger.error(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")

    finally:
        state.sync_in_progress = False


# =============================================================================
# FastAPI Application
# =============================================================================


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan events"""
    # Startup
    state.is_running = True
    state.config = WebConfig()

    # ë¡œê·¸ í•¸ë“¤ëŸ¬ ë“±ë¡
    ws_handler = WebSocketLogHandler(state)
    logging.getLogger("archive_analyzer").addHandler(ws_handler)

    # Issue #49: Sheets ë™ê¸°í™” ì–´ëŒ‘í„° ì´ˆê¸°í™” (ì„ íƒì )
    state.sheets_sync = _create_sheets_adapter()

    logger.info(f"Web ëª¨ë‹ˆí„°ë§ ì„œë²„ ì‹œì‘: http://{state.config.host}:{state.config.port}")

    yield

    # Shutdown
    state.is_running = False
    logger.info("Web ëª¨ë‹ˆí„°ë§ ì„œë²„ ì¢…ë£Œ")


def _create_sheets_adapter():
    """Sheets ì–´ëŒ‘í„° ìƒì„± (ì„ íƒì  ì´ˆê¸°í™”)

    Issue #49: Google Sheets ë™ê¸°í™” ì›¹ ëŒ€ì‹œë³´ë“œ ì—°ë™

    í™˜ê²½ë³€ìˆ˜ SHEETS_SYNC_ENABLED=true ì¼ ë•Œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤.
    ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ Noneì„ ë°˜í™˜í•˜ë©°, ê¸°ì¡´ ê¸°ëŠ¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    import os

    if os.environ.get("SHEETS_SYNC_ENABLED", "").lower() not in ("true", "1", "yes"):
        logger.info("Sheets ë™ê¸°í™” ë¹„í™œì„±í™” (SHEETS_SYNC_ENABLED ë¯¸ì„¤ì •)")
        return None

    try:
        from archive_analyzer.sheets_adapter import create_sheets_adapter

        adapter = create_sheets_adapter()
        if adapter:
            logger.info("Sheets ë™ê¸°í™” ì–´ëŒ‘í„° ì´ˆê¸°í™” ì„±ê³µ")
        return adapter
    except Exception as e:
        logger.warning(f"Sheets ë™ê¸°í™” ì–´ëŒ‘í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def create_app() -> FastAPI:
    """FastAPI ì•± ìƒì„±"""
    app = FastAPI(
        title="NAS Auto Sync Monitor",
        description="NAS ìë™ ë™ê¸°í™” ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ",
        version="1.0.0",
        lifespan=lifespan,
    )

    # í…œí”Œë¦¿ ë° ì •ì  íŒŒì¼
    templates_dir = Path(__file__).parent / "templates"
    static_dir = Path(__file__).parent / "static"
    dashboard_template = templates_dir / "dashboard.html"

    # í…œí”Œë¦¿ íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if dashboard_template.exists():
        templates = Jinja2Templates(directory=str(templates_dir))
    else:
        templates = None

    if static_dir.exists():
        app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

    # ==========================================================================
    # Routes
    # ==========================================================================

    @app.get("/", response_class=HTMLResponse)
    async def dashboard(request: Request):
        """ë©”ì¸ ëŒ€ì‹œë³´ë“œ"""
        if templates:
            return templates.TemplateResponse(
                "dashboard.html",
                {
                    "request": request,
                    "state": state,
                    "archive_stats": get_db_stats(state.config.archive_db),
                    "pokervod_stats": get_db_stats(state.config.pokervod_db),
                },
            )
        else:
            return get_embedded_dashboard()

    @app.get("/health")
    async def health_check():
        """í—¬ìŠ¤ ì²´í¬"""
        return {
            "status": "healthy" if state.is_running else "unhealthy",
            "sync_in_progress": state.sync_in_progress,
            "last_sync_time": state.last_sync_time.isoformat() if state.last_sync_time else None,
            "error": state.error_message,
        }

    @app.get("/api/status")
    async def get_status():
        """ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
        return {
            "is_running": state.is_running,
            "sync_in_progress": state.sync_in_progress,
            "last_sync_time": state.last_sync_time.isoformat() if state.last_sync_time else None,
            "last_sync_result": state.last_sync_result,
            "error_message": state.error_message,
            "config": {
                "archive_db": state.config.archive_db,
                "pokervod_db": state.config.pokervod_db,
                "nas_mount_path": state.config.nas_mount_path,
                "sync_interval": state.config.sync_interval,
            },
        }

    @app.get("/api/stats")
    async def get_stats():
        """DB í†µê³„ ì¡°íšŒ"""
        return {
            "archive": get_db_stats(state.config.archive_db),
            "pokervod": get_db_stats(state.config.pokervod_db),
        }

    @app.get("/api/history")
    async def get_history(limit: int = 50):
        """íŒŒì¼ ë³€ê²½ ì´ë ¥ ì¡°íšŒ"""
        return {
            "history": get_file_history(state.config.archive_db, limit),
        }

    @app.post("/api/sync")
    async def trigger_sync(background_tasks: BackgroundTasks):
        """ìˆ˜ë™ ë™ê¸°í™” íŠ¸ë¦¬ê±°"""
        if state.sync_in_progress:
            return JSONResponse(
                status_code=409,
                content={"error": "ë™ê¸°í™”ê°€ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤"},
            )

        background_tasks.add_task(run_sync_task)
        return {"message": "ë™ê¸°í™” ì‹œì‘ë¨", "status": "started"}

    @app.post("/api/reconcile")
    async def trigger_reconcile(background_tasks: BackgroundTasks, dry_run: bool = True):
        """ì •í•©ì„± ê²€ì¦ íŠ¸ë¦¬ê±°"""
        if state.sync_in_progress:
            return JSONResponse(
                status_code=409,
                content={"error": "ë‹¤ë¥¸ ì‘ì—…ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤"},
            )

        background_tasks.add_task(run_reconcile_task, dry_run)
        return {
            "message": "ì •í•©ì„± ê²€ì¦ ì‹œì‘ë¨",
            "status": "started",
            "dry_run": dry_run,
        }

    @app.get("/api/logs")
    async def get_logs(limit: int = 100):
        """ìµœê·¼ ë¡œê·¸ ì¡°íšŒ"""
        logs = list(state.log_buffer)[-limit:]
        return {"logs": logs}

    # =========================================================================
    # Issue #45: 1:1 ë§¤ì¹­ API
    # =========================================================================

    @app.get("/api/dashboard")
    async def get_dashboard():
        """í†µí•© ëŒ€ì‹œë³´ë“œ ë°ì´í„° (PRD 7.2)"""
        archive_stats = get_db_stats(state.config.archive_db)
        pokervod_stats = get_db_stats(state.config.pokervod_db)

        # ë§¤ì¹­ ìš”ì•½ ê³„ì‚°
        matching_summary = get_matching_summary(
            state.config.archive_db, state.config.pokervod_db
        )

        return {
            "source": {
                "name": "NAS ì•„ì¹´ì´ë¸Œ",
                "db_path": state.config.archive_db,
                "total_files": archive_stats.get("total_files", 0),
                "by_type": archive_stats.get("by_type", {}),
                "db_size_mb": archive_stats.get("db_size_mb", 0),
            },
            "target": {
                "name": "OTT í”Œë«í¼",
                "db_path": state.config.pokervod_db,
                "total_files": pokervod_stats.get("total_files", 0),
                "by_format": pokervod_stats.get("by_type", {}),
                "excluded": {
                    "non_hls": matching_summary.get("not_synced", 0),
                    "duplicates": matching_summary.get("duplicates", 0),
                },
            },
            "sync_status": {
                "is_running": state.sync_in_progress,
                "last_sync_time": state.last_sync_time.isoformat() if state.last_sync_time else None,
                "last_result": state.last_sync_result,
            },
            "catalogs": matching_summary.get("catalogs", []),
        }

    @app.get("/api/matching")
    async def get_matching(
        page: int = 1,
        per_page: int = 20,
        status: Optional[str] = None,
        sort_by: str = "filename",
        sort_order: str = "asc",
    ):
        """1:1 ë§¤ì¹­ í…Œì´ë¸” ë°ì´í„° (PRD 7.3, Issue #51: ì •ë ¬)"""
        items, total, summary = get_matching_items(
            state.config.archive_db,
            state.config.pokervod_db,
            page=page,
            per_page=per_page,
            status_filter=status,
            sort_by=sort_by,
            sort_order=sort_order,
        )

        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "items": items,
            "summary": summary,
        }

    @app.get("/api/matching/tree")
    async def get_matching_tree():
        """íŠ¸ë¦¬ êµ¬ì¡° ë§¤ì¹­ ë°ì´í„° (PRD 7.4)"""
        catalogs = get_catalog_tree(
            state.config.archive_db, state.config.pokervod_db
        )
        return {"catalogs": catalogs}

    # =========================================================================
    # Issue #49: Google Sheets ë™ê¸°í™” API
    # =========================================================================

    @app.get("/api/sheets/status")
    async def get_sheets_status():
        """Sheets ë™ê¸°í™” ìƒíƒœ ì¡°íšŒ

        Returns:
            enabled: Sheets ë™ê¸°í™” í™œì„±í™” ì—¬ë¶€
            status: ì—°ê²° ìƒíƒœ, ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê°„ ë“±
        """
        if not state.sheets_sync:
            return {
                "enabled": False,
                "message": "Sheets sync not configured (set SHEETS_SYNC_ENABLED=true)",
            }

        status = state.sheets_sync.get_status()
        return {
            "enabled": True,
            **status.to_dict(),
        }

    @app.post("/api/sheets/sync")
    async def trigger_sheets_sync(
        background_tasks: BackgroundTasks,
        direction: str = "db_to_sheets",
    ):
        """Sheets ë™ê¸°í™” íŠ¸ë¦¬ê±°

        Args:
            direction: ë™ê¸°í™” ë°©í–¥
                - db_to_sheets: DB â†’ Sheets
                - sheets_to_db: Sheets â†’ DB
                - hands: Archive Sheet â†’ hands í…Œì´ë¸”
                - bidirectional: ì–‘ë°©í–¥ (Sheets ìš°ì„ )
        """
        if not state.sheets_sync:
            return JSONResponse(
                status_code=400,
                content={"error": "Sheets sync not configured (set SHEETS_SYNC_ENABLED=true)"},
            )

        if state.sync_in_progress:
            return JSONResponse(
                status_code=409,
                content={"error": "Another sync is already in progress"},
            )

        def run_sheets_sync():
            state.sync_in_progress = True
            try:
                if direction == "db_to_sheets":
                    result = state.sheets_sync.sync_to_sheets()
                elif direction == "sheets_to_db":
                    result = state.sheets_sync.sync_from_sheets()
                elif direction == "hands":
                    result = state.sheets_sync.sync_hands()
                elif direction == "bidirectional":
                    result = state.sheets_sync.sync_bidirectional()
                else:
                    logger.warning(f"Unknown sync direction: {direction}")
                    return

                state.last_sync_result = {
                    "type": "sheets",
                    **result.to_dict(),
                }
                logger.info(f"Sheets ë™ê¸°í™” ì™„ë£Œ: {direction}")
            except Exception as e:
                logger.error(f"Sheets ë™ê¸°í™” ì˜¤ë¥˜: {e}")
                state.error_message = str(e)
            finally:
                state.sync_in_progress = False

        background_tasks.add_task(run_sheets_sync)
        return {
            "message": f"Sheets sync started ({direction})",
            "direction": direction,
            "status": "started",
        }

    @app.websocket("/ws/logs")
    async def websocket_logs(websocket: WebSocket):
        """ë¡œê·¸ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (WebSocket)"""
        await websocket.accept()
        state.connected_clients.append(websocket)

        try:
            # ê¸°ì¡´ ë¡œê·¸ ì „ì†¡
            for log in state.log_buffer:
                await websocket.send_text(log)

            # ì—°ê²° ìœ ì§€
            while True:
                await websocket.receive_text()
        except WebSocketDisconnect:
            pass
        finally:
            if websocket in state.connected_clients:
                state.connected_clients.remove(websocket)

    return app


def get_embedded_dashboard() -> HTMLResponse:
    """ë‚´ì¥ ëŒ€ì‹œë³´ë“œ HTML (Issue #45: 1:1 ë§¤ì¹­ UI, Issue #51: ì •ë ¬/ì‚¬ìœ )"""
    html = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NAS â†’ OTT ë™ê¸°í™” ëª¨ë‹ˆí„°</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .log-container { height: 300px; overflow-y: auto; font-family: monospace; font-size: 11px; }
        .status-dot { width: 10px; height: 10px; border-radius: 50%; display: inline-block; }
        .status-running { background-color: #22c55e; animation: pulse 2s infinite; }
        .status-stopped { background-color: #ef4444; }
        .status-syncing { background-color: #eab308; animation: pulse 1s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
        .tab-active { border-bottom: 2px solid #3b82f6; color: #3b82f6; }
        .matching-table { font-size: 13px; }
        .badge { padding: 2px 8px; border-radius: 4px; font-size: 11px; font-weight: 500; }
        .badge-synced { background: #166534; color: #86efac; }
        .badge-not-synced { background: #991b1b; color: #fca5a5; }
        .badge-duplicate { background: #854d0e; color: #fde047; }
        .badge-reason { background: #374151; color: #9ca3af; font-size: 10px; margin-left: 4px; }
        .sort-btn { cursor: pointer; user-select: none; }
        .sort-btn:hover { color: #60a5fa; }
        .sort-active { color: #3b82f6; }
        .folder-item { transition: all 0.2s; }
        .folder-item:hover { background: rgba(59, 130, 246, 0.1); }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 min-h-screen">
    <div class="container mx-auto px-4 py-6">
        <!-- Header -->
        <div class="flex justify-between items-center mb-6">
            <h1 class="text-2xl font-bold">ğŸ”„ NAS â†’ OTT ë™ê¸°í™” ëª¨ë‹ˆí„°</h1>
            <div id="status-indicator" class="flex items-center gap-2 text-sm">
                <span class="status-dot status-running"></span>
                <span>ì •ìƒ ë™ì‘ ì¤‘</span>
            </div>
        </div>

        <!-- Summary Cards (PRD 6.4) -->
        <div class="grid grid-cols-1 md:grid-cols-4 gap-4 mb-6">
            <!-- Source -->
            <div class="bg-gray-800 rounded-lg p-4">
                <div class="flex items-center gap-2 mb-2">
                    <span class="text-lg">ğŸ“‚</span>
                    <span class="text-sm text-gray-400">Source</span>
                </div>
                <div class="text-xs text-gray-500 mb-1">archive.db</div>
                <div id="source-count" class="text-2xl font-bold text-blue-400">-</div>
                <div class="text-xs text-gray-400">ì „ì²´ íŒŒì¼</div>
            </div>

            <!-- Arrow -->
            <div class="hidden md:flex items-center justify-center text-2xl text-gray-600">
                â†’â†’
            </div>

            <!-- Target -->
            <div class="bg-gray-800 rounded-lg p-4">
                <div class="flex items-center gap-2 mb-2">
                    <span class="text-lg">ğŸ“º</span>
                    <span class="text-sm text-gray-400">Target</span>
                </div>
                <div class="text-xs text-gray-500 mb-1">pokervod.db</div>
                <div id="target-count" class="text-2xl font-bold text-green-400">-</div>
                <div class="text-xs text-gray-400">HLS ë“±ë¡</div>
            </div>

            <!-- Actions -->
            <div class="bg-gray-800 rounded-lg p-4">
                <div class="text-sm text-gray-400 mb-2">ë™ê¸°í™”</div>
                <button onclick="triggerSync()" class="w-full bg-blue-600 hover:bg-blue-700 px-3 py-2 rounded text-sm mb-2">
                    ğŸ”„ ë™ê¸°í™” ì‹¤í–‰
                </button>
                <div id="last-sync" class="text-xs text-gray-500">-</div>
            </div>
        </div>

        <!-- Tabs -->
        <div class="flex gap-4 border-b border-gray-700 mb-4">
            <button id="tab-table" onclick="showTab('table')" class="px-4 py-2 tab-active">
                ğŸ“‹ 1:1 ë§¤ì¹­ í…Œì´ë¸”
            </button>
            <button id="tab-tree" onclick="showTab('tree')" class="px-4 py-2 text-gray-400 hover:text-gray-200">
                ğŸŒ³ ì¹´íƒˆë¡œê·¸ íŠ¸ë¦¬
            </button>
            <button id="tab-logs" onclick="showTab('logs')" class="px-4 py-2 text-gray-400 hover:text-gray-200">
                ğŸ“œ ë¡œê·¸
            </button>
        </div>

        <!-- Tab Content: Matching Table (PRD 6.2, Issue #51) -->
        <div id="content-table" class="bg-gray-800 rounded-lg p-4">
            <!-- Filter & Sort (Issue #51) -->
            <div class="flex flex-wrap gap-4 mb-4 text-sm">
                <select id="status-filter" onchange="loadMatching()" class="bg-gray-700 rounded px-3 py-1">
                    <option value="">ì „ì²´ ìƒíƒœ</option>
                    <option value="synced">âœ… ë™ê¸°í™”ë¨</option>
                    <option value="not_synced">âŒ ë¯¸ë“±ë¡</option>
                    <option value="synced_with_duplicates">âš ï¸ ì¤‘ë³µ</option>
                </select>
                <select id="sort-by" onchange="loadMatching()" class="bg-gray-700 rounded px-3 py-1">
                    <option value="filename">íŒŒì¼ëª…ìˆœ</option>
                    <option value="size">í¬ê¸°ìˆœ</option>
                    <option value="status">ìƒíƒœìˆœ</option>
                    <option value="path">ê²½ë¡œìˆœ</option>
                    <option value="modified_at">ìˆ˜ì •ì¼ìˆœ</option>
                </select>
                <select id="sort-order" onchange="loadMatching()" class="bg-gray-700 rounded px-3 py-1">
                    <option value="asc">ì˜¤ë¦„ì°¨ìˆœ â†‘</option>
                    <option value="desc">ë‚´ë¦¼ì°¨ìˆœ â†“</option>
                </select>
                <div id="matching-summary" class="text-gray-400 ml-auto"></div>
            </div>

            <!-- Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ ë³„ í†µê³„ -->
            <div id="reason-summary" class="flex gap-3 mb-4 text-xs text-gray-500"></div>

            <!-- Table -->
            <div class="overflow-x-auto">
                <table class="w-full matching-table">
                    <thead>
                        <tr class="text-left border-b border-gray-700 text-gray-400">
                            <th class="pb-2 w-24">ìƒíƒœ</th>
                            <th class="pb-2">ğŸ“‚ Source (archive.db)</th>
                            <th class="pb-2">ğŸ“º Target (pokervod.db)</th>
                            <th class="pb-2 w-16">ID</th>
                        </tr>
                    </thead>
                    <tbody id="matching-body">
                        <tr><td colspan="4" class="py-8 text-center text-gray-500">ë¡œë”© ì¤‘...</td></tr>
                    </tbody>
                </table>
            </div>

            <!-- Pagination -->
            <div class="flex justify-between items-center mt-4 text-sm">
                <div id="pagination-info" class="text-gray-400"></div>
                <div class="flex gap-2">
                    <button onclick="changePage(-1)" class="bg-gray-700 hover:bg-gray-600 px-3 py-1 rounded">â—€ ì´ì „</button>
                    <button onclick="changePage(1)" class="bg-gray-700 hover:bg-gray-600 px-3 py-1 rounded">ë‹¤ìŒ â–¶</button>
                </div>
            </div>
        </div>

        <!-- Tab Content: Tree View (PRD 6.3) -->
        <div id="content-tree" class="bg-gray-800 rounded-lg p-4 hidden">
            <div id="tree-container">
                <div class="text-gray-500">ë¡œë”© ì¤‘...</div>
            </div>
        </div>

        <!-- Tab Content: Logs -->
        <div id="content-logs" class="bg-gray-800 rounded-lg p-4 hidden">
            <div class="flex justify-between items-center mb-2">
                <span class="text-sm text-gray-400">ì‹¤ì‹œê°„ ë¡œê·¸</span>
                <button onclick="clearLogs()" class="text-xs bg-gray-700 hover:bg-gray-600 px-2 py-1 rounded">
                    Clear
                </button>
            </div>
            <div id="log-container" class="log-container bg-gray-950 rounded p-3 text-green-400">
                <div id="logs"></div>
            </div>
        </div>
    </div>

    <script>
        let currentPage = 1;
        const perPage = 20;

        // Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ  ë¼ë²¨
        const REASON_LABELS = {
            'hls_incompatible': 'ğŸ¬ HLS ë¹„í˜¸í™˜',
            'duplicate_excluded': 'ğŸ“‹ ì¤‘ë³µ ì œì™¸',
            'non_video': 'ğŸ“„ ë¹„ë””ì˜¤ ì•„ë‹˜',
            'pending_sync': 'â³ ë™ê¸°í™” ëŒ€ê¸°'
        };

        // Tab switching
        function showTab(tab) {
            ['table', 'tree', 'logs'].forEach(t => {
                document.getElementById('content-' + t).classList.toggle('hidden', t !== tab);
                document.getElementById('tab-' + t).classList.toggle('tab-active', t === tab);
                document.getElementById('tab-' + t).classList.toggle('text-gray-400', t !== tab);
            });
            if (tab === 'tree') loadTree();
        }

        // Load dashboard summary (Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ ë³„ í†µê³„)
        async function loadDashboard() {
            try {
                const res = await fetch('/api/dashboard');
                const data = await res.json();
                document.getElementById('source-count').textContent = data.source?.total_files || 0;
                document.getElementById('target-count').textContent = data.target?.total_files || 0;
                if (data.sync_status?.last_sync_time) {
                    document.getElementById('last-sync').textContent =
                        'ë§ˆì§€ë§‰: ' + new Date(data.sync_status.last_sync_time).toLocaleString('ko-KR');
                }

                // Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ ë³„ í†µê³„ (Summary APIì—ì„œ ê°€ì ¸ì˜´)
                const summaryRes = await fetch('/api/matching?page=1&per_page=1');
                const summaryData = await summaryRes.json();
                // í†µê³„ëŠ” ë³„ë„ API í•„ìš” - ì—¬ê¸°ì„œëŠ” ë¡œë“œì‹œ ê°±ì‹ í•˜ì§€ ì•ŠìŒ
            } catch (e) {
                console.error('Dashboard load error:', e);
            }
        }

        // Load matching table (Issue #51: ì •ë ¬ + ë¯¸ë“±ë¡ ì‚¬ìœ )
        async function loadMatching() {
            try {
                const status = document.getElementById('status-filter').value;
                const sortBy = document.getElementById('sort-by').value;
                const sortOrder = document.getElementById('sort-order').value;

                let url = `/api/matching?page=${currentPage}&per_page=${perPage}`;
                url += `&sort_by=${sortBy}&sort_order=${sortOrder}`;
                if (status) url += `&status=${status}`;

                const res = await fetch(url);
                const data = await res.json();

                // Summary
                const sum = data.summary || {};
                document.getElementById('matching-summary').innerHTML =
                    `âœ… ${sum.synced || 0} | âŒ ${sum.not_synced || 0} | âš ï¸ ${sum.synced_with_duplicates || 0}`;

                // Pagination
                const start = data.total > 0 ? (currentPage-1)*perPage + 1 : 0;
                const end = Math.min(currentPage*perPage, data.total);
                document.getElementById('pagination-info').textContent =
                    `${data.total}ê°œ ì¤‘ ${start}-${end}`;

                // Table
                const tbody = document.getElementById('matching-body');
                if (!data.items || data.items.length === 0) {
                    tbody.innerHTML = '<tr><td colspan="4" class="py-8 text-center text-gray-500">ë°ì´í„° ì—†ìŒ</td></tr>';
                    return;
                }

                tbody.innerHTML = data.items.map(item => {
                    const statusBadge = getStatusBadge(item.status, item.not_synced_reason);
                    const source = item.source || {};
                    const target = item.target;
                    const size = formatSize(source.size_bytes);

                    return `
                        <tr class="border-b border-gray-700/50 hover:bg-gray-700/30">
                            <td class="py-2">${statusBadge}</td>
                            <td class="py-2">
                                <div class="text-sm">${source.filename || '-'}</div>
                                <div class="text-xs text-gray-500 truncate max-w-md" title="${source.path || ''}">${source.path || ''}</div>
                                <div class="text-xs text-gray-600">${size} | ${item.is_hls_compatible ? 'HLS âœ“' : 'HLS âœ—'}</div>
                                ${item.duplicates?.length ? `<div class="text-xs text-yellow-600">+${item.duplicates.length} ì¤‘ë³µ</div>` : ''}
                            </td>
                            <td class="py-2">
                                ${target ? `
                                    <div class="text-sm text-green-400">${target.filename}</div>
                                    <div class="text-xs text-gray-500 truncate max-w-md">${target.nas_path || ''}</div>
                                ` : `<span class="text-gray-600">${getReasonText(item.not_synced_reason)}</span>`}
                            </td>
                            <td class="py-2 text-gray-500">${target?.id || '-'}</td>
                        </tr>
                    `;
                }).join('');
            } catch (e) {
                console.error('Matching load error:', e);
            }
        }

        // Issue #51: ë¯¸ë“±ë¡ ì‚¬ìœ  í…ìŠ¤íŠ¸
        function getReasonText(reason) {
            switch(reason) {
                case 'hls_incompatible': return 'HLS ë¹„í˜¸í™˜ í¬ë§·';
                case 'duplicate_excluded': return 'ì¤‘ë³µ ì œì™¸';
                case 'non_video': return 'ë¹„ë””ì˜¤ ì•„ë‹˜';
                case 'pending_sync': return 'ë™ê¸°í™” ëŒ€ê¸°';
                default: return 'ë¯¸ë“±ë¡';
            }
        }

        // Issue #51: ìƒíƒœ ë°°ì§€ (ë¯¸ë“±ë¡ ì‚¬ìœ  í¬í•¨)
        function getStatusBadge(status, reason) {
            switch(status) {
                case 'synced': return '<span class="badge badge-synced">âœ… ë™ê¸°í™”</span>';
                case 'not_synced':
                    const reasonLabel = reason ? `<span class="badge badge-reason">${getReasonText(reason)}</span>` : '';
                    return `<span class="badge badge-not-synced">âŒ ë¯¸ë“±ë¡</span>${reasonLabel}`;
                case 'synced_with_duplicates': return '<span class="badge badge-duplicate">âš ï¸ ì¤‘ë³µ</span>';
                default: return '<span class="badge bg-gray-600">?</span>';
            }
        }

        function formatSize(bytes) {
            if (!bytes) return '-';
            const gb = bytes / (1024 * 1024 * 1024);
            if (gb >= 1) return gb.toFixed(1) + ' GB';
            const mb = bytes / (1024 * 1024);
            return mb.toFixed(0) + ' MB';
        }

        function changePage(delta) {
            currentPage = Math.max(1, currentPage + delta);
            loadMatching();
        }

        // Load tree view (Issue #51: í´ë” íŠ¸ë¦¬ êµ¬ì¡°)
        async function loadTree() {
            try {
                const res = await fetch('/api/matching/tree');
                const data = await res.json();
                const container = document.getElementById('tree-container');

                if (!data.catalogs || data.catalogs.length === 0) {
                    container.innerHTML = '<div class="text-gray-500">ì¹´íƒˆë¡œê·¸ ì—†ìŒ</div>';
                    return;
                }

                container.innerHTML = data.catalogs.map(cat => `
                    <div class="mb-4">
                        <div class="flex items-center gap-2 cursor-pointer hover:bg-gray-700/50 p-2 rounded folder-item"
                             onclick="toggleCatalog('${cat.name}')">
                            <span id="icon-${cat.name}">ğŸ“</span>
                            <span class="font-medium">${cat.name}</span>
                            <span class="text-sm text-gray-400">(${cat.total_files} íŒŒì¼)</span>
                            <span class="text-xs text-green-500">âœ… ${cat.synced}</span>
                            <span class="text-xs text-red-500">âŒ ${cat.not_synced}</span>
                        </div>
                        <div id="folders-${cat.name}" class="hidden ml-4">
                            ${renderFolderTree(cat.children || [], cat.name)}
                        </div>
                    </div>
                `).join('');
            } catch (e) {
                console.error('Tree load error:', e);
            }
        }

        // Issue #51: ê³„ì¸µì  í´ë” íŠ¸ë¦¬ ë Œë”ë§ (1ë‹¨-2ë‹¨-3ë‹¨-4ë‹¨...)
        function renderFolderTree(folders, parentId, depth = 1) {
            if (!folders || folders.length === 0) return '';

            return folders.map((folder, idx) => {
                const folderId = `${parentId}-${idx}`;
                const hasChildren = folder.children && folder.children.length > 0;
                const hasFiles = folder.files && folder.files.length > 0;

                // ì¬ê·€ í†µê³„ ì‚¬ìš© (í•˜ìœ„ í´ë” í¬í•¨)
                const totalFiles = folder.total_files_recursive || folder.total_files || 0;
                const synced = folder.synced_recursive || folder.synced || 0;
                const syncPercent = totalFiles > 0 ? Math.round((synced / totalFiles) * 100) : 0;

                // depthì— ë”°ë¥¸ ë“¤ì—¬ì“°ê¸° ìƒ‰ìƒ
                const borderColors = ['border-gray-600', 'border-gray-700', 'border-gray-800', 'border-gray-900'];
                const borderColor = borderColors[Math.min(depth - 1, borderColors.length - 1)];

                return `
                    <div class="border-l ${borderColor} pl-3 mt-1">
                        <div class="flex items-center gap-2 cursor-pointer hover:bg-gray-700/30 p-1 rounded folder-item"
                             onclick="toggleFolder('${folderId}')">
                            <span id="icon-${folderId}">${hasChildren || hasFiles ? 'ğŸ“' : 'ğŸ“‚'}</span>
                            <span class="text-sm ${depth === 1 ? 'font-medium' : ''}">${folder.name}</span>
                            <span class="text-xs text-gray-500">(${totalFiles})</span>
                            <span class="text-xs ${syncPercent >= 80 ? 'text-green-400' : syncPercent >= 50 ? 'text-yellow-400' : 'text-red-400'}">
                                ${syncPercent}%
                            </span>
                            ${hasChildren ? `<span class="text-xs text-gray-600">â–¶</span>` : ''}
                        </div>
                        <div id="content-${folderId}" class="hidden ml-2">
                            ${hasChildren ? renderFolderTree(folder.children, folderId, depth + 1) : ''}
                            ${hasFiles ? `
                                <div class="border-l border-gray-800 pl-2 mt-1">
                                    ${folder.files.map(f => `
                                        <div class="flex items-center gap-2 text-xs py-0.5 hover:bg-gray-800/30">
                                            <span>${f.status === 'synced' ? 'âœ…' : 'âŒ'}</span>
                                            <span class="text-gray-400 truncate max-w-sm" title="${f.path || f.name}">${f.name}</span>
                                            <span class="text-gray-600">${formatSize(f.size_bytes)}</span>
                                        </div>
                                    `).join('')}
                                </div>
                            ` : ''}
                        </div>
                    </div>
                `;
            }).join('');
        }

        function toggleCatalog(name) {
            const folders = document.getElementById('folders-' + name);
            const icon = document.getElementById('icon-' + name);
            folders.classList.toggle('hidden');
            icon.textContent = folders.classList.contains('hidden') ? 'ğŸ“' : 'ğŸ“‚';
        }

        function toggleFolder(id) {
            const content = document.getElementById('content-' + id);
            const icon = document.getElementById('icon-' + id);
            if (content) {
                content.classList.toggle('hidden');
                icon.textContent = content.classList.contains('hidden') ? 'ğŸ“' : 'ğŸ“‚';
            }
        }

        // Actions
        async function triggerSync() {
            if (!confirm('ë™ê¸°í™”ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?')) return;
            try {
                const res = await fetch('/api/sync', { method: 'POST' });
                const data = await res.json();
                alert(data.message || data.error);
                loadDashboard();
            } catch (e) {
                alert('Error: ' + e.message);
            }
        }

        function clearLogs() {
            document.getElementById('logs').innerHTML = '';
        }

        // WebSocket for logs
        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const ws = new WebSocket(`${protocol}//${window.location.host}/ws/logs`);
            ws.onmessage = (event) => {
                const logsDiv = document.getElementById('logs');
                const line = document.createElement('div');
                line.textContent = event.data;
                logsDiv.appendChild(line);
                const container = document.getElementById('log-container');
                container.scrollTop = container.scrollHeight;
            };
            ws.onclose = () => setTimeout(connectWebSocket, 3000);
        }

        // Status check
        async function checkStatus() {
            try {
                const res = await fetch('/api/status');
                const data = await res.json();
                const indicator = document.getElementById('status-indicator');
                const dot = indicator.querySelector('.status-dot');
                const text = indicator.querySelector('span:last-child');

                if (data.sync_in_progress) {
                    dot.className = 'status-dot status-syncing';
                    text.textContent = 'ë™ê¸°í™” ì¤‘...';
                } else if (data.is_running) {
                    dot.className = 'status-dot status-running';
                    text.textContent = 'ì •ìƒ ë™ì‘ ì¤‘';
                } else {
                    dot.className = 'status-dot status-stopped';
                    text.textContent = 'ì¤‘ì§€ë¨';
                }
            } catch (e) {}
        }

        // Init
        loadDashboard();
        loadMatching();
        connectWebSocket();
        setInterval(loadDashboard, 30000);
        setInterval(checkStatus, 5000);
    </script>
</body>
</html>
    """
    return HTMLResponse(content=html)


# ê¸°ë³¸ ì•± ì¸ìŠ¤í„´ìŠ¤
app = create_app()


# =============================================================================
# CLI
# =============================================================================


def main():
    import argparse

    import uvicorn

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
    )

    parser = argparse.ArgumentParser(description="NAS Auto Sync Web Monitor")
    parser.add_argument("--host", default="0.0.0.0", help="Host (default: 0.0.0.0)")
    parser.add_argument("--port", type=int, default=8080, help="Port (default: 8080)")
    parser.add_argument("--reload", action="store_true", help="Enable auto-reload")

    args = parser.parse_args()

    uvicorn.run(
        "archive_analyzer.web.app:app",
        host=args.host,
        port=args.port,
        reload=args.reload,
    )


if __name__ == "__main__":
    main()
